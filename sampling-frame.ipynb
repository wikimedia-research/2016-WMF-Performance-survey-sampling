{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating raw frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wmfdata as wmf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIVE_SNAPSHOT = \"2020-07\"\n",
    "END_OF_DATA = \"2020-08-01 00:00:00\"\n",
    "DAYS_IN_LAST_3_MO = 92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This selects all active editors from the past three months.\n",
    "frame_query = \"\"\"\n",
    "-- TABLE OF\n",
    "with mo_edits as (\n",
    "    select\n",
    "        event_user_text as user,\n",
    "        year(event_timestamp) as year,\n",
    "        month(event_timestamp) as month,\n",
    "        sum(if(wiki_db = \"wikidatawiki\", 0.1, 1)) as edits\n",
    "    from wmf.mediawiki_history\n",
    "    where\n",
    "        -- REGISTERED\n",
    "        event_user_is_anonymous = false and\n",
    "        \n",
    "        -- NON-BOT\n",
    "        size(event_user_is_bot_by) = 0 and\n",
    "        not array_contains(event_user_groups, \"bot\") and\n",
    "        \n",
    "        -- CONTENT\n",
    "        page_namespace_is_content_historical = true and\n",
    "        \n",
    "        -- EDITS\n",
    "        event_entity = \"revision\" and\n",
    "        event_type = \"create\" and\n",
    "        \n",
    "        -- FROM THE LAST 3 MONTHS\n",
    "        unix_timestamp(event_timestamp, \"yyyy-MM-dd HH:mm:ss.0\") \n",
    "            > (unix_timestamp(\"{end_of_data}\") - (60 * 60 * 24 * {days_in_last_3_mo})) and\n",
    "\n",
    "        -- FROM THE LATEST SNAPSHOT\n",
    "        snapshot = \"{hive_snapshot}\"    \n",
    "    -- PER USER, PER MONTH\n",
    "    group by event_user_text, year(event_timestamp), month(event_timestamp)\n",
    "), \n",
    "\n",
    "-- TABLE OF\n",
    "yr_proj_edits as (\n",
    "    select\n",
    "        event_user_text as user,\n",
    "        wiki_db as proj,\n",
    "        sum(if(wiki_db = \"wikidatawiki\", 0.1, 1)) as edits,\n",
    "        max(event_timestamp) as latest_edit\n",
    "    from wmf.mediawiki_history\n",
    "    where\n",
    "        -- REGISTERED\n",
    "        event_user_is_anonymous = false and\n",
    "        \n",
    "        -- NON-BOT\n",
    "        size(event_user_is_bot_by) = 0 and\n",
    "        not array_contains(event_user_groups, \"bot\") and\n",
    "        \n",
    "        -- EDITS\n",
    "        event_entity = \"revision\" and\n",
    "        event_type = \"create\" and\n",
    "        \n",
    "        -- FROM THE LAST YEAR\n",
    "        unix_timestamp(event_timestamp, \"yyyy-MM-dd HH:mm:ss.0\") \n",
    "            > (unix_timestamp(\"{end_of_data}\") - (60 * 60 * 24 * 365)) and\n",
    "        \n",
    "        -- FROM THE LATEST SNAPSHOT\n",
    "        snapshot = \"{hive_snapshot}\"\n",
    "    \n",
    "    -- PER USER, PER WIKI\n",
    "    group by event_user_text, wiki_db\n",
    ")\n",
    "\n",
    "-- FINAL SELECT OF\n",
    "select \n",
    "    recent_actives.user as user,\n",
    "    yr_edits.proj as home_proj,\n",
    "    global_edits\n",
    "\n",
    "-- USERS ACTIVE IN 2 OF 3 MONTHS\n",
    "from (\n",
    "    select\n",
    "        user,\n",
    "        sum(if(edits >= 5, 1, 0)) as active_months\n",
    "    from mo_edits\n",
    "    where\n",
    "        -- WHO ARE NOT WMF STAFF\n",
    "        user not like \"%WMF%\"\n",
    "    group by user\n",
    "    having active_months >= 2\n",
    ") recent_actives\n",
    "\n",
    "-- JOINED TO THEIR HOME WIKI AND GLOBAL EDITS\n",
    "left join (\n",
    "    select\n",
    "        user,\n",
    "        proj,\n",
    "        -- in the unlikely event that wikis are tied by edit count and latest edit, \n",
    "        -- row_number() will break it somehow\n",
    "        row_number() over (partition by user order by edits desc, latest_edit desc) as rank,\n",
    "        sum(edits) over (partition by user) as global_edits\n",
    "    from yr_proj_edits\n",
    ") yr_edits\n",
    "on \n",
    "    recent_actives.user = yr_edits.user and\n",
    "    rank = 1\n",
    "\"\"\".format(\n",
    "  hive_snapshot = HIVE_SNAPSHOT,\n",
    "  end_of_data = END_OF_DATA,\n",
    "  days_in_last_3_mo = DAYS_IN_LAST_3_MO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_frame = wmf.spark.run(frame_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>home_proj</th>\n",
       "      <th>global_edits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aammiinn11</td>\n",
       "      <td>fawiki</td>\n",
       "      <td>486.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbe98</td>\n",
       "      <td>commonswiki</td>\n",
       "      <td>901.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahmad.aea.99</td>\n",
       "      <td>arwiki</td>\n",
       "      <td>2586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aineireland</td>\n",
       "      <td>enwiki</td>\n",
       "      <td>643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Altanner1991</td>\n",
       "      <td>enwiki</td>\n",
       "      <td>483.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user    home_proj  global_edits\n",
       "0    Aammiinn11       fawiki         486.3\n",
       "1        Abbe98  commonswiki         901.3\n",
       "2  Ahmad.aea.99       arwiki        2586.0\n",
       "3   Aineireland       enwiki         643.0\n",
       "4  Altanner1991       enwiki         483.4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_frame = raw_frame.assign(\n",
    "  global_edits=lambda df: df[\"global_edits\"].astype(\"float\")\n",
    ")\n",
    "\n",
    "raw_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limiting to emailable users and adding emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sql_tuple(iterable):\n",
    "  \"\"\"\n",
    "  Making an SQL 'tuple', for use in an IN clause, is hard. Doing it manually using \n",
    "  `\", \".join` requires a lot of messing around with quote marks and escaping. Using the\n",
    "  string representation of a Python tuple *almost* works, but fails when there's just\n",
    "  one element, because SQL doesn't accept the trailing comma that Python needs.\n",
    "  \n",
    "  What we really want is the string representation of a Python list, but using parentheses\n",
    "  instead of brackets. This function turns an iterable into just that.\n",
    "  \"\"\"\n",
    "  if type(iterable) != list:\n",
    "    iterable = [x for x in iterable]\n",
    "  \n",
    "  list_repr = repr(iterable)\n",
    "  list_repr = \"(\" + list_repr[1:-1] + \")\"\n",
    "\n",
    "  return list_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a tuple of the usernames. It isn't necessary to escape quotes because Python will\n",
    "# do this in an SQL-compatible way automatically.\n",
    "users = tuple(raw_frame[\"user\"].tolist())\n",
    "\n",
    "# Query centralauth.globaluser table in replicas to obtain email addresses\n",
    "# This seems to be more reliable that the user tables of individual wikis\n",
    "# since the global email address is what's shown to the user on every\n",
    "# local preferences page; if the address is changed on an individual wiki, \n",
    "# the global address and local address will be immediately updated but the\n",
    "# local addresses at other wikis may not be\n",
    "#\n",
    "# We also want confirmed email addresses only, since we don't want to email\n",
    "# people whose addresses have been used without their consent.\n",
    "email_query = f\"\"\"\n",
    "SELECT \n",
    "  gu_name AS user,\n",
    "  gu_email AS email\n",
    "FROM centralauth.globaluser\n",
    "WHERE\n",
    "  gu_name IN {users} AND\n",
    "  gu_email_authenticated IS NOT NULL AND\n",
    "  gu_email != \"\"\n",
    "\"\"\"\n",
    "\n",
    "user_emails = wmf.mariadb.run(\n",
    "  email_query,\n",
    "  dbs=\"centralauth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36484 entries, 0 to 36483\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   user    36484 non-null  object\n",
      " 1   email   36484 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 570.2+ KB\n"
     ]
    }
   ],
   "source": [
    "user_emails.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The left join will exclude users without confirmed email addresses.\n",
    "frame = pd.merge(user_emails, raw_frame, on=\"user\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "disablemail_fragments = []\n",
    "projects = frame[\"home_proj\"].unique()\n",
    "for proj in projects:\n",
    "  proj_users = frame.query(\"home_proj == @proj\")[\"user\"]\n",
    "  proj_users = make_sql_tuple(proj_users.tolist())\n",
    "  \n",
    "  props = wmf.mariadb.run(f\"\"\"\n",
    "  SELECT\n",
    "      user_name as user\n",
    "  FROM user\n",
    "  LEFT JOIN user_properties\n",
    "  ON user_id = up_user\n",
    "  WHERE\n",
    "    user_name in {proj_users} AND\n",
    "    up_property = \"disablemail\" AND\n",
    "    up_value = 1\n",
    "  \"\"\", dbs=proj)\n",
    "  \n",
    "  disablemail_fragments.append(props)\n",
    "\n",
    "disablemail_users = pd.concat(disablemail_fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "disablemail_list = disablemail_users[\"user\"].tolist()\n",
    "frame = frame.set_index(\"user\").drop(disablemail_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enriching frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project groups\n",
    "grouped_projects = pd.read_table(\"definitions/project-group-assignments.tsv\").drop(\"project_name\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = (\n",
    "  frame\n",
    "  .merge(grouped_projects, how = \"left\", left_on = \"home_proj\", right_on = \"project_key\" )\n",
    "  .drop(\"project_key\", axis = 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any project without an explcit assignment is in the \"other\" group\n",
    "frame[\"project_group\"] = frame[\"project_group\"].fillna(\"other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enwiki       10938\n",
       "commons       3218\n",
       "dewiki        2887\n",
       "cee_wps       2648\n",
       "frwiki        2220\n",
       "ruwiki        1757\n",
       "meaf_wps      1619\n",
       "jawiki        1500\n",
       "eswiki        1471\n",
       "other         1458\n",
       "weur_wps      1207\n",
       "zhwiki        1172\n",
       "itwiki        1027\n",
       "ptwiki         532\n",
       "nlwiki         518\n",
       "wikidata       488\n",
       "sasia_wps      421\n",
       "arwiki         348\n",
       "malay_wps      281\n",
       "asia_wps       248\n",
       "kowiki         241\n",
       "viwiki         197\n",
       "metawiki        90\n",
       "Name: project_group, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame[\"project_group\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed any identified users. This consists of a combination of the \"2019 contributor opt-outs\" and the \"Dashboard Leaders by home wiki 2018-2019\" as our opt-out list.\n",
    "\n",
    "For the 2019 Sampling pull, we decided to pull additional users from each target project. We excluded users in the first sample pulled to get only new users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are users who are program leaders or who opted out in the past\n",
    "optouts = pd.read_table(\"secrets/optouts.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10670"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_remove = frame[frame[\"user\"].isin(optouts)].index\n",
    "\n",
    "# How many users are we removing?\n",
    "len(to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = frame.drop(to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_len = len(frame[\"user\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are all our users unique?\n",
    "frame.user.nunique() == frame_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are all our users in a group?\n",
    "frame.groupby(\"project_group\")[\"user\"].count().sum() == frame_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do we have the 23 groups we want?\n",
    "frame[\"project_group\"].nunique() == 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This file now contains senstive information.\n",
    "frame.to_csv(\"secrets/sampling-frame.tsv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
